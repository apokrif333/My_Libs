{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course \n",
    "Author: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). Edited by Sergey Kolchenko (@KolchenkoSergey). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Assignment #6\n",
    "### <center> Beating baselines in \"How good is your Medium article?\"\n",
    "    \n",
    "<img src='../../img/medium_claps.jpg' width=40% />\n",
    "\n",
    "\n",
    "[Competition](https://www.kaggle.com/c/how-good-is-your-medium-article). The task is to beat \"A6 baseline\" (~1.45 Public LB score). Do not forget about our shared [\"primitive\" baseline](https://www.kaggle.com/kashnitsky/ridge-countvectorizer-baseline) - you'll find something valuable there.\n",
    "\n",
    "**Your task:**\n",
    " 1. \"Freeride\". Come up with good features to beat the baseline \"A6 baseline\" (for now, public LB is only considered)\n",
    " 2. You need to name your [team](https://www.kaggle.com/c/how-good-is-your-medium-article/team) (out of 1 person) in full accordance with the [course rating](https://drive.google.com/open?id=19AGEhUQUol6_kNLKSzBsjcGUU3qWy3BNUg8x8IFkO3Q). You can think of it as a part of the assignment. 16 credits for beating the mentioned baseline and correct team naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from scipy import sparse\n",
    "from html.parser import HTMLParser\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# from scipy.sparse import csr_matrix, hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will help to throw away all HTML tags from an article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supplementary function to read a JSON line without crashing on escape characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_line(line=None):\n",
    "    result = None\n",
    "    try:        \n",
    "        result = json.loads(line)\n",
    "    except Exception as e:      \n",
    "        # Find the offending character index:\n",
    "        idx_to_replace = int(str(e).split(' ')[-1].replace(')',''))      \n",
    "        # Remove the offending character:\n",
    "        new_line = list(line)\n",
    "        new_line[idx_to_replace] = ' '\n",
    "        new_line = ''.join(new_line)     \n",
    "        return read_json_line(line=new_line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features `content`, `published`, `title` and `author`, write them to separate files for train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_write(path_to_data, inp_filename, is_train=True):\n",
    "    prefix = 'train' if is_train else 'test'\n",
    "\n",
    "    content_test = []\n",
    "    # vector = TfidfVectorizer(ngram_range=(1, 2), max_features=100_000)\n",
    "    with open(os.path.join(path_to_data, inp_filename), encoding='utf-8') as inp_json_file:\n",
    "        for line in tqdm(inp_json_file):\n",
    "            json_data = read_json_line(line)\n",
    "\n",
    "            features['title'] += [json_data['title']]\n",
    "            features['author'] += [re.split(r'@', json_data['author']['url'])[1]]\n",
    "            features['reading_t'] += re.findall(r'\\d+', json_data['meta_tags']['twitter:data1'])\n",
    "\n",
    "            tag_search = re.findall(r\"/medium.com/tag/(.+?)(?:\\?source|\\\"|\\/)\", json_data['content'])\n",
    "            features['tags'] += [' '.join(tag_search)]\n",
    "\n",
    "            published_split = re.split(r'T', json_data['published']['$date'])\n",
    "            features['date'] += [published_split[0]]\n",
    "            features['time'] += [re.split(r\"\\.\", published_split[1])[0]]\n",
    "\n",
    "            content_no_html = strip_tags(json_data['content'].replace('\\n', ' ').replace('\\r', ' '))\n",
    "            content_space_char = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", content_no_html)\n",
    "            content_space_point = re.sub(r\"(\\.)([A-Z])\", r\"\\1 \\2\", content_space_char)\n",
    "            content_space_digits = re.sub(r\"(\\d+)(\\w+)\", r\"\\1 \\2\", content_space_point)\n",
    "            content_space_quest = re.sub(r\"(\\?)(\\w+)\", r\"\\1 \\2\", content_space_digits)\n",
    "            features['content'] += [content_space_quest]\n",
    "\n",
    "        for feature in features.keys():\n",
    "            with open(os.path.join(path_to_data, prefix + '_' + feature + '_pickle'), 'wb') as pick:\n",
    "                pickle.dump(features[feature], pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = 'C:/Users/Tom/PycharmProjects/Start/GibHub/Jupyter_Notebook/data_6/'\n",
    "features = {'content': [], 'title': [], 'tags': [], 'author': [], 'date': [], 'time': [], 'reading_t': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features_and_write(PATH_TO_DATA, 'train.json', is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features_and_write(PATH_TO_DATA, 'test.json', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the following groups of features:**\n",
    "    - Tf-Idf with article content (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
    "    - Tf-Idf with article titles (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
    "    - Time features: publication hour, whether it's morning, day, night, whether it's a weekend\n",
    "    - Bag of authors (i.e. One-Hot-Encoded author names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 62313/62313 [03:25<00:00, 302.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 34645/34645 [01:52<00:00, 308.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Векторизируем\n",
    "def vector(data):\n",
    "    vector = TfidfVectorizer(ngram_range=(1, 2), max_features=100_000)\n",
    "    return vector.fit_transform(tqdm(data))\n",
    "\n",
    "\n",
    "# vec_features = {'train': features, 'test': features}\n",
    "# for typez in vec_features.keys():\n",
    "#     for feature in features.keys():\n",
    "#         with open(os.path.join(PATH_TO_DATA, typez + '_' + feature + '_pickle'), 'rb') as pick:\n",
    "#             data = pickle.load(pick)\n",
    "#             vec_features[typez][feature] = vector(data)\n",
    "            \n",
    "with open(os.path.join(PATH_TO_DATA, 'train_content_pickle'), 'rb') as pick:\n",
    "    data = pickle.load(pick)\n",
    "    X_train_cont = vector(data)\n",
    "    \n",
    "with open(os.path.join(PATH_TO_DATA, 'test_content_pickle'), 'rb') as pick:\n",
    "    data = pickle.load(pick)\n",
    "    X_test_cont = vector(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join all sparse matrices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = hstack([X_train_content_sparse, X_train_title_sparse,\n",
    "                         X_train_author_sparse, \n",
    "                         X_train_time_features_sparse]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sparse = hstack([X_test_content_sparse, X_test_title_sparse,\n",
    "                        X_test_author_sparse, \n",
    "                        X_test_time_features_sparse]).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read train target and split data for validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_log1p_recommends.csv'), \n",
    "                           index_col='id')\n",
    "y_train = train_target['log_recommends'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_size = int(0.7 * train_target.shape[0])\n",
    "X_train_part = X_train_cont[:train_part_size, :]  # X_train_sparse[:train_part_size, :]\n",
    "y_train_part = y_train[:train_part_size]\n",
    "X_valid = X_train_cont[train_part_size:, :]  # X_train_sparse[train_part_size:, :]\n",
    "y_valid = y_train[train_part_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18694\n",
      "(18694, 100000)\n"
     ]
    }
   ],
   "source": [
    "print(len(y_valid))\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a simple Ridge model and check MAE on the validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18694\n",
      "18694\n",
      "18694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c1a476e898>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(random_state=17)\n",
    "ridge.fit(X_train_part, y_train_part)\n",
    "ridge_pred = ridge.predict(X_valid)\n",
    "\n",
    "print(len(y_valid))\n",
    "print(X_valid.shape[0])\n",
    "print(len(ridge_pred))\n",
    "\n",
    "plt.hist(y_valid, bins=30, alpha=0.5, color='red', label='true', range=(0, 10))\n",
    "plt.hist(ridge_pred, bins=30, alpha=0.5, color='green', label='pred', range=(0, 10))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the same Ridge with all available data, make predictions for the test set and form a submission file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1534047529371754 2.168964102495093\n"
     ]
    }
   ],
   "source": [
    "# You code here\n",
    "valid_mae = mean_absolute_error(y_valid, ridge_pred)\n",
    "print(valid_mae, np.expm1(valid_mae))\n",
    "\n",
    "ridge.fit(X_train_cont, y_train)\n",
    "ridge_test_pred = ridge.predict(X_test_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_file(prediction, filename, path_to_sample=os.path.join(PATH_TO_DATA, 'sample_submission.csv')):\n",
    "    submission = pd.read_csv(path_to_sample, index_col='id')\n",
    "    \n",
    "    submission['log_recommends'] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34645,)\n"
     ]
    }
   ],
   "source": [
    "print(ridge_test_pred.shape)\n",
    "write_submission_file(ridge_test_pred, os.path.join(PATH_TO_DATA, 'assignment6_medium_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now's the time for dirty Kaggle hacks. Form a submission file with all zeroes. Make a submission. What do you get if you think about it? How is it going to help you with modifying your predictions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(np.zeros_like(ridge_test_pred), \n",
    "                      os.path.join(PATH_TO_DATA,\n",
    "                                   'medium_all_zeros_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify predictions in an appropriate way (based on your all-zero submission) and make a new submission.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_test_pred_modif = ridge_test_pred # You code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(ridge_test_pred_modif, \n",
    "                      os.path.join(PATH_TO_DATA,\n",
    "                                   'assignment6_medium_submission_with_hack.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for the assignment. Much more credits will be given to the winners in this competition, check [course roadmap](https://mlcourse.ai/roadmap). Do not spoil the assignment and the competition - don't share high-performing kernels (with MAE < 1.5).\n",
    "\n",
    "Some ideas for improvement:\n",
    "\n",
    "- Engineer good features, this is the key to success. Some simple features will be based on publication time, authors, content length and so on\n",
    "- You may not ignore HTML and extract some features from there\n",
    "- You'd better experiment with your validation scheme. You should see a correlation between your local improvements and LB score\n",
    "- Try TF-IDF, ngrams, Word2Vec and GloVe embeddings\n",
    "- Try various NLP techniques like stemming and lemmatization\n",
    "- Tune hyperparameters. In our example, we've left only 50k features and used C=1 as a regularization parameter, this can be changed\n",
    "- SGD and Vowpal Wabbit will learn much faster\n",
    "- Play around with blending and/or stacking. An intro is given in [this Kernel](https://www.kaggle.com/kashnitsky/ridge-and-lightgbm-simple-blending) by @yorko \n",
    "- In our course, we don't cover neural nets. But it's not obliged to use GRUs/LSTMs/whatever in this competition.\n",
    "\n",
    "Good luck!\n",
    "\n",
    "<img src='../../img/kaggle_shakeup.png' width=50%>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
